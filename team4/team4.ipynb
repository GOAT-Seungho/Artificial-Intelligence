{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training_D1_60k\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing_D2_10k\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing_D3\":\n",
    "        fname_img = os.path.join(path, 'testall-images-idx3-ubyte')\n",
    "    elif dataset is \"training_new_10k\":\n",
    "        fname_img = os.path.join(path, 'new1k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'new1k-labels-idx1-ubyte')\n",
    "    elif dataset is \"training_D1_D2_new_10k\":\n",
    "        fname_img = os.path.join(path, 'newtrain-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'newtrain-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise Exception(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "pyplot.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, \n",
    "                          normalize=False, \n",
    "                          title='Confusion matrix', \n",
    "                          cmap=pyplot.cm.Blues):\n",
    "#     ***\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalizaton can be applied by setting 'normalize=True'.\n",
    "#     ***\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    \n",
    "    pyplot.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    pyplot.title(title)\n",
    "    pyplot.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    pyplot.xticks(tick_marks, classes, rotation=45)\n",
    "    pyplot.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        pyplot.text(j, i, format(cm[i,j], fmt),\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "        \n",
    "    pyplot.tight_layout()\n",
    "    pyplot.ylabel('True label')\n",
    "    pyplot.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1 : train 60k\n",
    "train_D1 = list(read(\"training_D1_60k\", \"./data\"))\n",
    "X_train_D1, y_train_D1 = [], []\n",
    "for i in range(len(train_D1)):\n",
    "    X_train_D1.append(np.ravel(train_D1[i][1]))\n",
    "    y_train_D1.append(train_D1[i][0])\n",
    "\n",
    "# new_10k : train 10k\n",
    "train_new_10k = list(read(\"training_new_10k\", \"./data\"))\n",
    "X_train_new_10k, y_train_new_10k = [], []\n",
    "for i in range(len(train_new_10k)):\n",
    "    X_train_new_10k.append(np.ravel(train_new_10k[i][1]))\n",
    "    y_train_new_10k.append(train_new_10k[i][0])\n",
    "    \n",
    "# total_train : D1 + D2 + new_10k -> We will use for training data (80k)\n",
    "total_train = list(read(\"training_D1_D2_new_10k\", \"./data\"))\n",
    "X_train_total, y_train_total = [], []\n",
    "for i in range(len(total_train)):\n",
    "    X_train_total.append(np.ravel(total_train[i][1]))\n",
    "    y_train_total.append(total_train[i][0])\n",
    "\n",
    "    \n",
    "# test_D2 : test 10k\n",
    "test_D2 = list(read(\"testing_D2_10k\", \"./data\"))\n",
    "X_test_D2, y_test_D2 = [], []\n",
    "for i in range(len(test_D2)):\n",
    "    X_test_D2.append(np.ravel(test_D2[i][1]))\n",
    "    y_test_D2.append(test_D2[i][0])\n",
    "\n",
    "# # test_D3 : D2 + new 50k -> We will use for testing data (60k)\n",
    "# test_D3 = list(read(\"testing_D3\", \"./data\"))\n",
    "# X_test_D3, y_test_D3 = [], []\n",
    "# for i in range(len(test_D3)):\n",
    "#     X_test_D3.append(np.ravel(test_D3[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBSGDClassifier(object):\n",
    "    \"\"\" Mini-Batch Stochastic Gradient Descent\n",
    "    \n",
    "    매개변수\n",
    "    -------\n",
    "    learning_rate : float (defalut = 0.1)\n",
    "        학습률 (0.0 과 1.0 사이)\n",
    "    max_iter : int (default = 100)\n",
    "        훈련 데이터셋 최대 반복 횟수\n",
    "    batch_size : int (defalut = 32)\n",
    "        Mini-Batch 크기\n",
    "    C : float (defalue = 1.0)\n",
    "        규제 파라미터 (1/lambda)\n",
    "        반드시 양수여야 한다. (Must be positive)\n",
    "    random_state : int (defalut = 1)\n",
    "        가중치 무작위 초기화를 위한 난수 생성기 시드\n",
    "        \n",
    "        \n",
    "    속성\n",
    "    ------\n",
    "    w_ : 1d-array\n",
    "        학습된 가중치\n",
    "    b_ : float\n",
    "        학습된 편향(bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=32, max_iter=100, learning_rate=0.1, random_state=1, C=1.0):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.C = C\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # 예외 처리\n",
    "        if self.C < 0:\n",
    "            raise ValueError(\"The C value of %r must be positive\" % self.C)\n",
    "        if ((learning_rate < 0) or (learning_rate > 1)):\n",
    "            raise ValueError(\"The learning_rate value of %r is invalid. Set the learning_rate value between 0.0 and 1.0.\" % learning_rate)\n",
    "            \n",
    "        # w, b 값 초기화\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=len(X))\n",
    "        self.b_ = 0\n",
    "        \n",
    "        # 입력한 최대 실행 횟수 만큼 실행\n",
    "        for e in range(self.max_iter):\n",
    "            \n",
    "            # F_prime_w : w에 대한 F' (w에 대한 F 미분)\n",
    "            # 최종 F'_w, F'_b 계산에 필요한 F'_w_i, F'_b_i의 합 \n",
    "            F_prime_w_i_sum = 0\n",
    "            F_prime_b_i_sum = 0\n",
    "            \n",
    "            # 데이터 랜덤 셔플\n",
    "            X_y_zip = [[x,y] for x, y in zip(X, y)]\n",
    "            rgen.shuffle(X_y_zip)\n",
    "            \n",
    "            # 배치 개수 설정 : 데이터의 총 개수 / 배치 사이즈  ->  # mnist_train : 60000 / 32 = 1875\n",
    "                # 질문 : 데이터의 개수 가 배치 사이즈로 안나눠떨어질 경우는 어떻게 해야하나?\n",
    "            n_batches = int(len(X_y_zip) / self.batch_size)\n",
    "            \n",
    "            # 배치의 개수 만큼 -> mnist_train : 1875\n",
    "            for j in range(n_batches):\n",
    "                # 설정한 배치 사이즈만큼 배치를 설정해준다. (defalut : 32 이므로 0~31, 32~63, ...)\n",
    "                X_y_zip_mini = X_y_zip[j*self.batch_size : (j+1)*self.batch_size]\n",
    "                X_mini = [n[0] for n in X_y_zip_mini]\n",
    "                y_mini = [n[1] for n in X_y_zip_mini]\n",
    "                \n",
    "                # 각 배치의 사이즈 만큼 (defalut : 32)\n",
    "                for k in range(self.batch_size):\n",
    "                    X_mini_k = X_mini[k]\n",
    "                    y_mini_k = y_mini[k]\n",
    "                    # 식의 이해를 돕기 위해 & 변수 명을 간단히 하기 위해, X_i, y_i 사용\n",
    "                    y_i = y_mini_k # y_i는 한 데이터 (784개로 이루어진) 마다 모두 동일\n",
    "                    \n",
    "                    # X는 784개의 원소로 이루어져 있으므로 각각 X_i를 계산해주기 위해 for문을 한 번 더 사용\n",
    "                    for i in range(len(X_mini)): \n",
    "                        X_i = X_mini_k[i]\n",
    "                        hyperplane = np.dot(X_i, self.w_) + self.b_\n",
    "                        \n",
    "                        \"\"\"\n",
    "                        에러 발생\n",
    "                        ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
    "                        \"\"\"\n",
    "                        if ((y_i*hyperplane).all() < 1):\n",
    "                            F_prime_w_i = (-1)*y_i*X_i + (1 / self.C)*self.w_\n",
    "                            F_prime_b_i = (-1)*y_i\n",
    "                        else:\n",
    "                            F_prime_w_i = (1 / self.C) * self.w_\n",
    "                            F_prime_b_i = 0\n",
    "                \n",
    "                        F_prime_w_i_sum += F_prime_w_i\n",
    "                        F_prime_b_i_sum += F_prime_b_i\n",
    "                \n",
    "                \n",
    "            F_prime_w = (1 / self.batch_size) * F_prime_w_i_sum\n",
    "            F_prime_b = (1 / self.batch_size) * F_prime_b_i_sum\n",
    "                \n",
    "            # 최종 가중치, 편향 업데이트\n",
    "            self.w_ = self.w_ - self.learning_rate * F_prime_w\n",
    "            self.b_ = self.b_ - self.learning_rate * F_prime_b\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Z = np.zeros((np.shape(X)[0]))\n",
    "        for i in enumerate(X):\n",
    "            Z[i] = np.dot(X[i], self.w_) + self.b_\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-377-a664668a9408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmbsgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMBSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmbsgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_new_10k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new_10k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-376-2532953a179a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# 각 배치의 사이즈 만큼 (defalut : 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mX_mini_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_mini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                     \u001b[0my_mini_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_mini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0;31m# 식의 이해를 돕기 위해 & 변수 명을 간단히 하기 위해, X_i, y_i 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "mbsgd=MBSGDClassifier(learning_rate=0.1)\n",
    "mbsgd.fit(X_train_new_10k, y_train_new_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
